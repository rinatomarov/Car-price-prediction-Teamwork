{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/final-dataset/sample_submission.csv\n/kaggle/input/final-dataset/yy2201.csv\n/kaggle/input/final-dataset/data2201.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport string\nfrom nltk.util import ngrams\nfrom collections import Counter\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\ndef mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR = '../input/final-dataset/'\nVAL_SIZE   = 0.20\nrandom_seed = 42\ndata = pd.read_csv(DIR+'data2201.csv')\nprice = pd.read_csv(DIR+'yy2201.csv')\nsample_submission = pd.read_csv(DIR+'sample_submission.csv')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop('Unnamed: 0', axis=1)\nX = data.query('sample == 1').drop(['sample'], axis=1)\nX_sub = data.query('sample == 0').drop(['sample'], axis=1)\ny = price['price']","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['modelDate', 'numberOfDoors',\n 'productionDate',\n 'engineDisplacement',\n 'enginePower',\n 'mileage',\n 'Владельцы',\n 'bT_length',\n 'Nalog',\n 'years_old']","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, random_state=random_seed)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[num_cols] = sc.fit_transform(X_train[num_cols])\nX_test[num_cols] = sc.transform(X_test[num_cols])\nX_sub[num_cols] = sc.transform(X_sub[num_cols])","execution_count":9,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  isetter(loc, value[:, i].tolist())\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  isetter(loc, value[:, i].tolist())\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pred = X_sub.values\nX = X.values\ny = y.values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n#data = data.drop('Unnamed: 0', axis=1)\n#X = data.query('sample == 1').drop(['sample'], axis=1)\n#X_sub = data.query('sample == 0').drop(['sample'], axis=1)\n#y = price['price']","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=5, shuffle=True, random_state=42)\n\ndef compute_metric(regr, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n    regr.fit(X_train, y_train)\n    y_test_pred = regr.predict(X_test)\n    return np.round(mape(y_test, y_test_pred)*100, 3)\n\ndef compute_meta_feature2(regr, X_train, X_test, y_train, cv, X_pred):    \n    \n    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \n\n    splits = cv.split(X_train)\n    for train_fold_index, predict_fold_index in splits:\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n        \n        folded_regr = clone(regr)\n        folded_regr.fit(X_fold_train, y_fold_train)\n        \n        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\n    \n    meta_regr = clone(regr)\n    meta_regr.fit(X_train, y_train)\n    \n    X_meta_test = meta_regr.predict(X_test)\n    X_meta_pred = meta_regr.predict(X_pred)\n    \n    return X_meta_train, X_meta_test, X_meta_pred","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_meta_features2(regr_s, X_train, X_test, y_train, cv, X_pred):\n   \n    features = [compute_meta_feature2(regr, X_train, X_test, y_train, cv, X_pred) for regr in tqdm(regr_s)]    \n    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\n    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\n    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\n    return stacked_features_train, stacked_features_test, stacked_features_pred","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\nfrom tqdm.notebook import tqdm\nfrom sklearn.base import clone","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features2([\n    RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \n                          max_features='sqrt',max_depth=77, bootstrap=True, random_state=42),\n    AdaBoostRegressor(random_state=42),\n    ExtraTreesRegressor(random_state=42),\n    RandomForestRegressor(random_state=42)], X_train, X_test, y_train, cv, X_pred)\n\nregr = RandomForestRegressor(\n n_estimators=300,\n min_samples_split=2,\n min_samples_leaf=1,\n max_features='sqrt',\n max_depth=77,\n bootstrap=True, \n random_state=42)\n\nprint(f'Stacking MAPE = {compute_metric(regr, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test, y_test=y_test)}%')","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8b86a3263644388879f1980c457d4bf"}},"metadata":{}},{"output_type":"stream","text":"\nStacking MAPE = 12.012%\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-7501aa11547d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Stacking MAPE = {compute_metric(regr, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test, y_test=y_test)}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredict_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'submission_stacking.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(X_sub)\nsample_submission['price'] = predict_submission\nsample_submission.to_csv(f'submission_stacking.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}